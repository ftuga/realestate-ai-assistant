[2025-04-17T03:50:51.809+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: zephyr_real_estate_model_dag.fine_tune_model manual__2025-04-17T03:50:38.315722+00:00 [queued]>
[2025-04-17T03:50:51.813+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: zephyr_real_estate_model_dag.fine_tune_model manual__2025-04-17T03:50:38.315722+00:00 [queued]>
[2025-04-17T03:50:51.813+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 4
[2025-04-17T03:50:51.820+0000] {taskinstance.py:1350} INFO - Executing <Task(PythonOperator): fine_tune_model> on 2025-04-17 03:50:38.315722+00:00
[2025-04-17T03:50:51.823+0000] {standard_task_runner.py:57} INFO - Started process 418 to run task
[2025-04-17T03:50:51.825+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'zephyr_real_estate_model_dag', 'fine_tune_model', 'manual__2025-04-17T03:50:38.315722+00:00', '--job-id', '11', '--raw', '--subdir', 'DAGS_FOLDER/Download_model.py', '--cfg-path', '/tmp/tmp6nryutxw']
[2025-04-17T03:50:51.825+0000] {standard_task_runner.py:85} INFO - Job 11: Subtask fine_tune_model
[2025-04-17T03:50:51.852+0000] {task_command.py:410} INFO - Running <TaskInstance: zephyr_real_estate_model_dag.fine_tune_model manual__2025-04-17T03:50:38.315722+00:00 [running]> on host 8793e6621b44
[2025-04-17T03:50:51.888+0000] {taskinstance.py:1568} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='zephyr_real_estate_model_dag' AIRFLOW_CTX_TASK_ID='fine_tune_model' AIRFLOW_CTX_EXECUTION_DATE='2025-04-17T03:50:38.315722+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-04-17T03:50:38.315722+00:00'
[2025-04-17T03:50:51.888+0000] {Download_model.py:99} INFO - PyTorch patched for compatibility
[2025-04-17T03:50:51.977+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.9/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(

[2025-04-17T03:50:53.071+0000] {cextension.py:77} WARNING - The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.
[2025-04-17T03:50:53.108+0000] {Download_model.py:215} INFO - Loading tokenizer...
[2025-04-17T03:50:53.334+0000] {Download_model.py:231} INFO - CUDA not available. Falling back to CPU mode.
[2025-04-17T03:50:53.464+0000] {logging_mixin.py:149} WARNING - Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]
[2025-04-17T03:50:53.485+0000] {Download_model.py:475} ERROR - Error in LoRA fine-tuning: [enforce fail at alloc_cpu.cpp:117] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 28966928384 bytes. Error code 12 (Cannot allocate memory)
[2025-04-17T03:50:53.486+0000] {Download_model.py:476} ERROR - Traceback (most recent call last):
  File "/opt/***/dags/Download_model.py", line 236, in fine_tune_model
    model = AutoModelForCausalLM.from_pretrained(
  File "/home/***/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 571, in from_pretrained
    return model_class.from_pretrained(
  File "/home/***/.local/lib/python3.9/site-packages/transformers/modeling_utils.py", line 279, in _wrapper
    return func(*args, **kwargs)
  File "/home/***/.local/lib/python3.9/site-packages/transformers/modeling_utils.py", line 4399, in from_pretrained
    ) = cls._load_pretrained_model(
  File "/home/***/.local/lib/python3.9/site-packages/transformers/modeling_utils.py", line 4793, in _load_pretrained_model
    caching_allocator_warmup(model_to_load, expanded_device_map, factor=2 if hf_quantizer is None else 4)
  File "/home/***/.local/lib/python3.9/site-packages/transformers/modeling_utils.py", line 5803, in caching_allocator_warmup
    _ = torch.empty(byte_count // factor, dtype=torch.float16, device=device, requires_grad=False)
RuntimeError: [enforce fail at alloc_cpu.cpp:117] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 28966928384 bytes. Error code 12 (Cannot allocate memory)

[2025-04-17T03:50:53.487+0000] {taskinstance.py:1847} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 181, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 198, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/Download_model.py", line 236, in fine_tune_model
    model = AutoModelForCausalLM.from_pretrained(
  File "/home/airflow/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 571, in from_pretrained
    return model_class.from_pretrained(
  File "/home/airflow/.local/lib/python3.9/site-packages/transformers/modeling_utils.py", line 279, in _wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/transformers/modeling_utils.py", line 4399, in from_pretrained
    ) = cls._load_pretrained_model(
  File "/home/airflow/.local/lib/python3.9/site-packages/transformers/modeling_utils.py", line 4793, in _load_pretrained_model
    caching_allocator_warmup(model_to_load, expanded_device_map, factor=2 if hf_quantizer is None else 4)
  File "/home/airflow/.local/lib/python3.9/site-packages/transformers/modeling_utils.py", line 5803, in caching_allocator_warmup
    _ = torch.empty(byte_count // factor, dtype=torch.float16, device=device, requires_grad=False)
RuntimeError: [enforce fail at alloc_cpu.cpp:117] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 28966928384 bytes. Error code 12 (Cannot allocate memory)
[2025-04-17T03:50:53.491+0000] {taskinstance.py:1368} INFO - Marking task as UP_FOR_RETRY. dag_id=zephyr_real_estate_model_dag, task_id=fine_tune_model, execution_date=20250417T035038, start_date=20250417T035051, end_date=20250417T035053
[2025-04-17T03:50:53.498+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 11 for task fine_tune_model ([enforce fail at alloc_cpu.cpp:117] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 28966928384 bytes. Error code 12 (Cannot allocate memory); 418)
[2025-04-17T03:50:53.520+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 1
[2025-04-17T03:50:53.533+0000] {taskinstance.py:2674} INFO - 0 downstream tasks scheduled from follow-on schedule check
